{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'contest', 'full_name', 'ledb_candid', 'fips', 'geo_name',\n",
       "       'year', 'votes', 'vote_share', 'incumbent', 'winner', 'n_winners',\n",
       "       'prob_democrat', 'prob_republican', 'pid_est', 'prob_male',\n",
       "       'prob_female', 'gender_est', 'prob_black', 'prob_white',\n",
       "       'prob_hispanic', 'prob_asian', 'prob_other', 'race_est',\n",
       "       'contributor.cfscore', 'percent_women', 'percent_white',\n",
       "       'percent_black', 'percent_hispanic', 'percent_asian_american',\n",
       "       'candidate_count', 'cpi_prevYear', 'unemployment_prevYear',\n",
       "       'pid_est_knn', 'gender_est_knn', 'race_est_knn', 'female', 'c_female',\n",
       "       'c_democrats', 'c_republicans', 'c_white', 'c_hispanic', 'c_black',\n",
       "       'c_asian', 'c_other'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Features engineering***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['c_female'] = df['gender_est'].map(lambda val: 1 if val == 'F' else 0)\n",
    "df['c_democrats'] = df['pid_est'].map(lambda val: 1 if val == 'D' else 0)\n",
    "df['c_republicans'] = df['pid_est'].map(lambda val: 1 if val == 'R' else 0)\n",
    "df['c_white'] = df['race_est'].map(lambda val: 1 if val == 'caucasian' else 0)\n",
    "df['c_hispanic'] = df['race_est'].map(lambda val: 1 if val == 'hispanic' else 0)\n",
    "df['c_black'] = df['race_est'].map(lambda val: 1 if val == 'black' else 0)\n",
    "df['c_asian'] = df['race_est'].map(lambda val: 1 if val == 'asian' else 0)\n",
    "df['c_other'] = df['race_est'].map(lambda val: 1 if val == 'other' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Features matrix***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_m1 = ['incumbent']\n",
    "\n",
    "features_m2 = ['incumbent', 'candidate_count']\n",
    "\n",
    "features_m3 = ['incumbent', 'candidate_count', 'female',\n",
    "               'c_democrats', 'c_republicans',\n",
    "               'c_white', 'c_hispanic', 'c_black', 'c_asian', 'c_other']\n",
    "\n",
    "features_m3 = ['incumbent', 'candidate_count', 'female',\n",
    "               'c_democrats', 'c_republicans',\n",
    "               'c_white', 'c_hispanic', 'c_black', 'c_asian', 'c_other',\n",
    "               'percent_women', 'percent_white']\n",
    "\n",
    "features_m4 = ['incumbent', 'candidate_count', 'female',\n",
    "               'c_democrats', 'c_republicans',\n",
    "               'c_white', 'c_hispanic', 'c_black', 'c_asian', 'c_other',\n",
    "               'percent_women', 'percent_white',\n",
    "               'cpi_prevYear', 'unemployment_prevYear']\n",
    "\n",
    "features_m5 = ['incumbent', 'candidate_count', 'pid_est_knn', 'gender_est_knn', 'race_est_knn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Logistic regression and hyperparameter***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(df, features):\n",
    "    split_index = int(0.8 * len(df))\n",
    "    train_df = df.iloc[:split_index]\n",
    "    test_df = df.iloc[split_index:]\n",
    "\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df['winner']\n",
    "\n",
    "    X_test = test_df[features]\n",
    "    y_test = test_df['winner']\n",
    "\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100], #inverse of the regularization strength, prevent overfitting\n",
    "        'penalty': ['l1', 'l2'], #Lasso-like, Ridge-like, mix 'elasticnet'\n",
    "        'solver': ['liblinear', 'saga'] #solved optimization. Other: 'lbfgs', 'newton-cg', 'sag'\n",
    "    }\n",
    "\n",
    "    # GridSearchCV with cross-validation\n",
    "    grid = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy')\n",
    "    # cv is cross validation\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"Best Parameters:\", grid.best_params_)\n",
    "\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = grid.best_estimator_.predict(X_test)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Accuracy: 0.8788167938931297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.92      0.90      0.91       717\n",
      "         win       0.80      0.82      0.81       331\n",
      "\n",
      "    accuracy                           0.88      1048\n",
      "   macro avg       0.86      0.86      0.86      1048\n",
      "weighted avg       0.88      0.88      0.88      1048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic(df, features_m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Accuracy: 0.8778625954198473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.91      0.91      0.91       717\n",
      "         win       0.80      0.81      0.81       331\n",
      "\n",
      "    accuracy                           0.88      1048\n",
      "   macro avg       0.86      0.86      0.86      1048\n",
      "weighted avg       0.88      0.88      0.88      1048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic(df, features_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Accuracy: 0.8807251908396947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.91      0.91      0.91       717\n",
      "         win       0.81      0.82      0.81       331\n",
      "\n",
      "    accuracy                           0.88      1048\n",
      "   macro avg       0.86      0.86      0.86      1048\n",
      "weighted avg       0.88      0.88      0.88      1048\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logistic(df, features_m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Accuracy: 0.8702290076335878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.90      0.91      0.91       717\n",
      "         win       0.80      0.79      0.79       331\n",
      "\n",
      "    accuracy                           0.87      1048\n",
      "   macro avg       0.85      0.85      0.85      1048\n",
      "weighted avg       0.87      0.87      0.87      1048\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py310/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic(df, features_m4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Accuracy: 0.8759541984732825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        lose       0.91      0.91      0.91       717\n",
      "         win       0.80      0.81      0.80       331\n",
      "\n",
      "    accuracy                           0.88      1048\n",
      "   macro avg       0.86      0.86      0.86      1048\n",
      "weighted avg       0.88      0.88      0.88      1048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# features with KNN\n",
    "\n",
    "logistic(df, features_m5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variance and covariance: we want high variance => help feature selections\n",
    "\n",
    "EDA (variance covairance / histograms / )\n",
    "\n",
    "hyperparameters\n",
    "\n",
    "report\n",
    "\n",
    "bias audit\n",
    "\n",
    " search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
